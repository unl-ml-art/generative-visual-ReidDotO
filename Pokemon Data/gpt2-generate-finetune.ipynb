{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7LoMj4GA4n_"
   },
   "source": [
    "#  GPT-2 Generation and Fine-Tuning\n",
    "\n",
    "This is adjusted for use in Reid Brockmeier's (rbrockmeier2@unl.edu) generative-text project. Most of the unused segments were removed, and other changes were mostly adjustments of values.\n",
    "\n",
    "This notebook explores GPT-2 (Generative Pretrained Transformer-2) from OpenAI. Read more about it [here](https://openai.com/blog/better-language-models/).\n",
    "\n",
    "Activities include:\n",
    "\n",
    "0. Setup\n",
    "1. Generate samples from pre-trained gpt-3 model\n",
    "2. Fine-tune gpt-2 on text of your choosing. \n",
    "\n",
    "Adapted by Robert Twomey (rtwomey@unl.edu) for Machine Learning for the Arts SP22 from this [google colab](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) by [Max Woolf](http://minimaxir.com). See his repo [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run once to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q gpt-2-simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restart the kernel and run the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KBkpRgBCBS2_"
   },
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the memory usage (0MiB / 32510MiB) for the Tesla V100.\n",
    "You can re-rerun the above cell to see what memory your code/models are using during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wXB05bPDYxS"
   },
   "source": [
    "## Downloading GPT-2\n",
    "\n",
    "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
    "\n",
    "There are three released sizes of GPT-2:\n",
    "\n",
    "* `124M` (default): the \"small\" model, 500MB on disk.\n",
    "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
    "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
    "\n",
    "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
    "\n",
    "The next cell downloads it from Google Cloud Storage and saves it in the the current working directory at `/models/<model_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8wSlgXoDPCR",
    "outputId": "10fc0d7c-d18f-4e11-a2af-bfade8b537eb"
   },
   "outputs": [],
   "source": [
    "model_name = \"355M\" # largest model we can fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run once to download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 951Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 3.72Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 1.54Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:32, 44.0Mit/s]                                 \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.16Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.17Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 4.78Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQAN3M6RT7Kj"
   },
   "source": [
    "# 1. Generate Text From The Pretrained Model\n",
    "\n",
    "If you want to generate text from the pretrained model pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`. (This is currently the only way to generate text from the 774M or 1558M models with this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "BAe4NpKNUj2C",
    "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 00:23:03.153183: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-04 00:23:04.429042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/355M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.load_gpt2(sess, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the model\n",
    "The follow cell samples from gpt-2, using the provided prefix (seed) and other parameters. It starts the TF session and generates the samples.\n",
    "\n",
    "Try changing the parameters below to change the output: \n",
    "- `prefix` is the prompt. This will be the starting string/seed for your generation. Use your own text. \n",
    "- `temperature` sets the variability/randomness of the output. Range 0.0-1.0\n",
    "- `length` sets the lenght of output (in tokens). max is 1024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "-xInIZKaU104",
    "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charizard used her Legendary Skill to save her brother, who was knocked unconscious by a blast of electricity.\n",
      "\n",
      "Pokémon\n",
      "\n",
      "Pokémon Emerald\n",
      "\n",
      "Pokémon Emerald is the first game in which the player begins the game as a male. It is the first game to feature the player as a female, though this is later changed to a male in Generation VI.\n",
      "\n",
      "Trainer Pokémon\n",
      "\n",
      "Pokémon Emerald's first Pokémon is Jigglypuff, which first appeared in the opening. In the anime, it was\n",
      "====================\n",
      "Charizard used a Dragon Pulse to try and knock out her, but it was too late as her Dragon Tail was absorbed by it.\n",
      "\n",
      "The three of them then watched as a group of Dragon-type Pokémon emerged from the lake. The Pokémon were all in their twenties, each wearing a purple shirt and a black pantsuit. The leader of the group, a young man wearing a blue shirt and black pantsuit, looked like he had a long time to live, but he was already dead.\n",
      "\n",
      "\n",
      "====================\n",
      "Charizard used the move Water Gun on Ash's Pikachu. The move's effects, including its ability to hit multiple targets, were intended to be extremely powerful, but the Pokémon's accuracy was surprisingly poor.\n",
      "\n",
      "The move was used by Ash's Pikachu in The Dream of Pikachu.\n",
      "\n",
      "The move was used by Ash's Pikachu in the anime.\n",
      "\n",
      "The move was used by Pikachu in the manga.\n",
      "\n",
      "The move was used by Pikachu in the Pokémon Adventures manga.\n",
      "\n",
      "The move was used\n",
      "====================\n",
      "Charizard used to be a villain in the show. In season three he was used as the villain for the last two episodes.\n",
      "\n",
      "In the season three episode \"The Battle of the Five Gods,\" the villains used a Star Wars reference to use Super Mario Bros. as their attack.\n",
      "\n",
      "In the episode \"The Final Battle,\" the villains used a Star Wars reference to use Super Mario Bros. as their attack.\n",
      "\n",
      "In the episode \"Mushroom Hill,\" the villains used a Star Wars reference\n",
      "====================\n",
      "Charizard used a Dragon Claw, but it was ineffective against Roserade.\n",
      "\n",
      "In the Pokémon XD anime\n",
      "\n",
      "In the manga\n",
      "\n",
      "In the Pokémon Adventures manga\n",
      "\n",
      "Giovanni's Magearna was used by Professor Oak in his battle against Team Rocket. It was first seen in A Peek Behind the Veil.\n",
      "\n",
      "In the Pokémon Gold and Silver: The Golden Boys manga\n",
      "\n",
      "In the Pokémon Diamond and Pearl Adventure! manga\n",
      "\n",
      "In the Pokémon Pocket Monsters manga\n",
      "\n",
      "In\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              model_name=model_name,\n",
    "              prefix=\"Charizard used\",\n",
    "              length=100,\n",
    "              temperature=0.7,\n",
    "              top_p=0.9,\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities\n",
    "- try varying the prefix. \n",
    "  - what length of prefix works best with the given model? \n",
    "  - how does the choice of prefix change the format/form of the output.\n",
    "- try varying the temperature.\n",
    "- try loading the different sized models (124M, 355M, 774M, 1558M) and generate text without changing the other parameters. \n",
    "  - Do you notice any qualitative differences in the output? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fine-Tuning GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already generated with gpt2, you need to reset the tf graph and gpt2 session. Otherwise, we create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "a3c75caa-917b-4818-ca2d-d78610d8b6f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 00:23:16.363019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"355M\" # same model as selected above\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# check if sess exists (e.g. if we ran section 1 above)\n",
    "var_exists = 'sess' in locals() or 'sess' in globals()\n",
    "\n",
    "if not var_exists:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeeSKtNWUedE"
   },
   "source": [
    "## Upload a text file\n",
    "For this, we will use a text file you provide to finetune (continue training) GPT-2. You can use any plain text (.txt) file. \n",
    "\n",
    "Simply drag and dropy our text file into the file browser at left. \n",
    "\n",
    "Once you have uploaded your file, update the file name in the cell below, then run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6OFnPCLADfll"
   },
   "outputs": [],
   "source": [
    "file_name = \"pokemon.txt\" # Text file containing the title data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Run the finetuning\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every `save_every` steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them. If your input text is smaller, training might proceed more quickly.\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
    "\n",
    "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
    "* **`sample_every`**: Number of steps to print example output\n",
    "* **`print_every`**: Number of steps to print training progress.\n",
    "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
    "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
    "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For larger models, the recommended finetune() parameters are:\n",
      "\tuse_memory_saving_gradients = True\n",
      "\tonly_train_transformer_layers = True\n",
      "\taccumulate_gradients = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 00:23:21.795047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/355M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 314036 tokens\n",
      "Training...\n",
      "[10 | 26.26] loss=1.38 avg=1.38\n",
      "[20 | 46.09] loss=1.11 avg=1.25\n",
      "[30 | 65.90] loss=1.10 avg=1.19\n",
      "======== SAMPLE 1 ========\n",
      " can't even do the same thing with the same colors? Or are we really limited in terms of color that we're able to give to those that want to use them?\n",
      "\n",
      "Is there an absolute limit on colors?\n",
      "\n",
      "So how does color actually work?\n",
      "\n",
      "It's kind of hard. I've seen it in the movies, and it's very difficult but not impossible. It seems as if each color is only a subset of the whole spectrum. We have our entire spectrum right now (but it's far, far more than that) that we can use to create a color. We call it a spectrum. Each color has a small amount of the same amount of it. In particular, yellow, red, green, blue and purple. Those three colors we used to make a yellow, red and gray color called Tangerine. That color is basically yellow, red and grey, with something in between. When you mix that up some of the energy that goes into that makes red and green, and it takes that energy and combines that with the energy from green and red, and creates that energy and creates that light green in the middle. So it takes those three energy sources, and you can put that out of proportion in any number of different ways to create that energy.\n",
      "\n",
      "When the sunlight hits a particular color it has that energy mixed in that is also yellow, because it's a yellow and it's a red color. You can put this energy in there which makes a green. And you can bring it together, and then you will see that green. For the most part yellow creates more yellow, red creates more orange, purple creates more green. You don't need to add anything else that goes in between to make a green or red. It's just the same amount of energy that went into the yellow and you can just use that energy to make the green. It's like the energy that made the red orange. You have this energy and you can use it to produce that energy, and you also turn it into a red. It takes the old red energy, and turns it into the red but there's different ways to make those different colors. There's a whole spectrum of the energy you can create and it's all part of our entire spectrum right now. It's basically just what you just described.\n",
      "\n",
      "Is it even possible, though?\n",
      "\n",
      "It doesn't really matter, really. If we were to find an unlimited way to create any given color (say, red), it could. It could be like this, if I wanted to create a red, but it's only the red from a red.\n",
      "\n",
      "We'll never know what it is with a red because it can only change color from the sun. It can change from yellow and orange, but it takes all the sun-energy it's received in the air in that point and then it transforms all that into a red. As far as we know red is the only color. There is an amount of energy that's available for that at any given time that we can use to create another color, but that only takes, you could say, about one of the most energy from the energy that comes from the sun.\n",
      "\n",
      "So that's a lot of energy to just think about, so if all we did is just look at the color red, we can create red because the amount of energy in the sky is equal. You don't have to spend energy to make that energy, you just need to be at that spot.\n",
      "\n",
      "So all the energy just for making red (if you had to imagine it without adding in that red) it would have to add up to about 400kJ, not too bad, I guess. The sun takes all those energy, and is converted to that red energy.\n",
      "\n",
      "Well at least with yellow, that makes a yellow color.\n",
      "\n",
      "Yellow, yellow, yellow.\n",
      "\n",
      "Yellow, yellow—that's what we call it.\n",
      "\n",
      "We can make any type of color.\n",
      "\n",
      "Yellow, yellow—that's what we call it.\n",
      "\n",
      "It's funny, too.\n",
      "\n",
      "Well, yellow is another type of energy. I want you to think about it for a moment. Yellow is energy in its purest and purest form. This is the same energy that is created by the sun. The sun is just the source of all green energy, but the sun can take almost whatever we put into the green and convert it to yellow. Or you could do a little experiment, and think about all the green that the sun makes from the reds and blues that it gets. A lot of it is lost in the atmosphere. It doesn't get converted to anything. That's a waste. Let's think of reds and blues. There are blue-red and blue-blue. The blue is basically our orange, we think of it because it's very orange. The other ones are called yellow and green.\n",
      "\n",
      "I'm sure you're not thinking this yet because we're\n",
      "\n",
      "[40 | 101.74] loss=1.11 avg=1.17\n",
      "[50 | 121.61] loss=0.97 avg=1.13\n",
      "[60 | 141.49] loss=1.02 avg=1.11\n",
      "======== SAMPLE 1 ========\n",
      "OUKFUS,THEWISH,SITUATIONISLAND,THREADSHOT,TORNADO,VOIDBEAST\n",
      "I don't really like when I have to use spells, because it's just like, \"oh, you wanna take care of me but you don't wanna need that?\" But, if it comes to it, it is okay since I'm good at taking care of myself. Also: a good way to take a shot is either when I'm getting hit or when I'm not. If you hit the target, then you get to attack without taking any damage.\n",
      "When shooting is done, you can put in time by pressing F11, so when you get to a certain location, you can start shooting at a particular spot. The best part is it takes 3 seconds.\n",
      "There are lots of ways, and not only spells, as well. Here are some things that are really good in the game, but can be a little slow:\n",
      "ROTOGUN. This weapon deals very powerful shots, and even the enemies you don't think will attack you.\n",
      "AARON. This guy is actually the hero of this story. The story is a bit short, I guess. It's a good and easy hero that will get you a lot of experience.\n",
      "ICHIBI ROUNDS. I guess this thing is really good. It's like it can do anything you want! It can do a lot because it grows faster than most enemies.\n",
      "I'm sure you can hear what they say, \"When it's the end, it works hard.\"\n",
      "It's not about being slow, of course. It's really good at everything you can do.\n",
      "It's also a good weapon, that's for sure.\n",
      "I thought it was so cute. I was so worried it is fast too, though.\n",
      "Just look at that head! It's so cute.\n",
      "ROCKETPLAN. The enemies are fast now and are weak because of my speed.\n",
      "It's the best weapon that you can get, just like this is the best you can get.\n",
      "This is probably the most difficult weapon.\n",
      "This kind of makes me feel like I can't get this weapon in any other way. In this game, the enemies are so fast that you get to go a lot of distance.\n",
      "I don't really use them much, though. They're used mainly for jumping.\n",
      "They can do one long jump.\n",
      "You can do them and have them slow the enemies too and be able to do other things to them too. They help you get close. (Laughs)\n",
      "I'm glad that you like them this much. (Laughs)\n",
      "You can see, it's the biggest. It's really big.\n",
      "Umm… you can't touch it. It's not even a toy. It's like, \"there is a bigger toy in this world!\"\n",
      "GIROU. It's a big sword.\n",
      "You can feel the sword swing on your back. I really love it.\n",
      "There's nothing like it. There is something different about this one.\n",
      "FOCUSING MUDSCAPE. This is like this really big mud. Then you'll be able to walk with this, too.\n",
      "It makes you think. It's a very simple thing, but you can think of it almost like magic…\n",
      "FOCUSING MUDSCAPES. This is like a normal Mud. It's always there. But this one is really strange since the Mud is really big. It's like it is holding a big boulder.\n",
      "They hold the bouldered mud inside. They will never let go without it.\n",
      "This is an ability that I'm very skilled in. Because I have to, in order to get things done.\n",
      "It can also cause you to get carried away.\n",
      "So when you are in a situation that you can't move, and you have to do it, you can use it.\n",
      "HANGOOSE. The horns of this guy are really strong.\n",
      "It's really big. You'll know soon if you're close to it.\n",
      "It's a good thing. When it's strong, then it will stop fighting.\n",
      "It's an extremely strong enemy.\n",
      "You can hear other people's battle cries.\n",
      "I thought if I beat its horn sound like the horn of an elephant, then I would've gotten much more than this.\n",
      "The other battles are really easy. But… when you're in close quarters, it's really difficult.\n",
      "I have to be careful with the surroundings. I can't play with them.\n",
      "In this game, you don't have many friends.\n",
      "I have only one friend, but you can't have too much friends. It can happen sometimes that people get in trouble and you don't have much friends. You just have to play through the game normally.\n",
      "I don't mind that. I'm really happy to get friends.\n",
      "\n",
      "\n",
      "[70 | 175.37] loss=1.12 avg=1.12\n",
      "[80 | 195.24] loss=1.07 avg=1.11\n",
      "[90 | 215.11] loss=0.93 avg=1.09\n",
      "======== SAMPLE 1 ========\n",
      "0XF5\n",
      "6.B3 B7\n",
      "2Bd5 1/2e8\n",
      "18...h6 {I won't play a bit by myself, so we won't have to worry.}\n",
      "19.Qd2\n",
      "Bxd3 {I don't have a solution to this. It's really close.}\n",
      "[Event \"28th Indian Premier Blitz 2016\"] [Site \"Hyderabad\"] [Date \"2016.11.29\"] [Round \"5\"] [White \"Akhwinder Singh Dhindkar, SCR\"] [Black \"Shadabh Yadav, ENG\"] [Result \"1-0\"] [ECO \"B20\"] [WhiteElo \"2561\"] [BlackElo \"2682\"] [Annotator \"Kramnik,Aleksandra\"] [PlyCount \"99\"] [EventDate \"2016.??.??\"] [EventType \"tourn\"] [EventRounds \"5\"] [EventCountry \"INR\"] [SourceDate \"2017.01.14\"] 11.f3 e6 12.Bd4 Nf6 13.Nf3 f5 14.a3 e6 15.Qf3 Qd8 16.Nf3 d6 17.Qxb1 Bb6 18.Rad1 g5 {It takes some time to come here, it's one of those rare positions, the defense's almost hopeless. I'm sure it's a mistake and he'll learn from it. It is my dream to keep playing in the next round. I still have another round.} (18...Qd8 {After 20...b5 {would be a little risky, but let's see if he takes up the idea, even if it's just on paper, it's a win, it's very scary} 19.Nd8 Bdxc5 20.Nxc5 Nc6 21.O-O-O Rd8 22.Rb1 Nb5 {Well, Black's not doing it.} 22.Rb7 Nd7 23.Ra4 Nc6 24.Kf1 Be6 25.Ke2 Nc4 26.Bb5 {Now Black has the initiative, but White needs to get the queen to e2!} (26...Nxa1 {was amazing, Black is really happy about what he did!}) 29.Kf1 Qc4 {It's Black's last move and he can't win.}) (26.Ba2 Qd7 27.Nxa7 Bxc1+ + {White has to move the king, but Black's very close!}) 25...dxe5 26.Ne4 Nc6 27.Na4 Rfe8 {It was very difficult to find a good move! The only difference is that White has to play very defensively. I feel the pressure.} Kg8 28.Qf3 g6 29.Nxg5 Nc5+ 30.Kg3 Ra6 31.Nf3 Nf6 {After 30...exd4, White's just in real trouble.}) 26...Qc4-xb6 27.Bb5 Ke6 28.Qb4+ Qe5 29.exd2 Nxe5+ 30.Rxe5 Bf7 31.Rc3 (31.Re2 Rxc1+ {was very nice, just not good enough. It was hard to see what a good move would be. A5 is a good move, but White has not found it until now, but if he could move his bishop into a3, that would be fantastic.}) 31...Nf6+ 32.Bg6 Qe7 33.Rc1 Rxe7 34.Rc2 Bd7 35.Rxa7 Rxa7 36.Rc5 Nf6+ 37.b4 Bb7 38.Qa5 Qe4?! { (8.29 → 9.20) Inaccuracy. Best move was Nxd5. } (38.Nxd5 dxc5 39.Nxd5 Rxd5 40.Nf3 Rg7+) 38...Nxf6 39.Nd5 Rd6+ 40.Qxf6 Qd8+ 41.Rd3 Rxh8+ 42.Rb5 Rxe7+ 43.Rl3 Qf5+ 44.Rxf6+ Kh8 45.Rxh9 h5 46.Rxe4+ Kf7 47.Rg6+ Kh6 48.Rg7 Qf6+ 49.Rxf6 Qf6 50.Rg8 Rg8 51.Rh8+ Qf6 52.Kg1 Qb7 53.Kj1 Bg8 54.Kg2 Qf7 55.Rg5# {It's not the end. White's not\n",
      "\n",
      "[100 | 248.98] loss=0.89 avg=1.07\n",
      "Saving checkpoint/run1/model-100\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name=model_name,\n",
    "              steps=100,\n",
    "              restore_from='fresh', # change to 'latest' to resume\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              learning_rate=1e-5,\n",
    "              sample_every=33,\n",
    "              save_every=100\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXSuTNERaw6K"
   },
   "source": [
    "## Notes on finetuning\n",
    "\n",
    "Keep an eye on the loss, and how quickly it is dropping. A too-rapid drop in loss could be a sign of overfitting, and a learning rate (lr) that is too high. \n",
    "\n",
    "After the model is trained, you can download the checkpoint folder to save your work. Training checkpoints are saved to `checkpoint/run1` (or whatever you chose for the run name above).\n",
    "\n",
    "You can compress it to a rar file and download that. Ask the instructor how.\n",
    "\n",
    "You're done! Feel free to go to the Generate Text From The Trained Model section to generate text based on your retrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already generated with gpt2, you need to reset the tf graph and gpt2 session. Otherwise, we create a new one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "# 3. Generate Text From The Finetuned Model\n",
    "\n",
    "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "82574eaa-d39a-4665-b611-e5172848da57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP\n",
      "\n",
      "The Bengals didn't elect to take a shot at the Bengals' defensive tackle, but they did let him go after he failed to make the team.\n",
      "\n",
      "A source with knowledge of the situation tells PFT that the Bengals have settled on the veteran tackle from the team's practice squad to start at free safety. The move is a way to try to get a production-level player off their hands.\n",
      "\n",
      "The only player with anything close to a real shot at the start of the season was the injury-prone Owa Odighizuwa, who managed only five tackles in seven games after the practice squad. But the presence of Chris Carter, the second-string tackle at free safety, and Anthony Johnson, who has played in six games in his first year in the league, should help.\n",
      "\n",
      "Carter, who has been on the practice squad the past three seasons, is the highest-paid veteran on the team.\n",
      "\n",
      "A fourth-round pick of the Bengals out of Arkansas in 2012, Carter has played in 15 games in his career. He has played 92 percent of Cincinnati's defensive snaps.\n",
      "\n",
      "A sixth-round pick of the Bengals in 2012, Johnson was traded to the Giants in exchange for a 2015 second-round pick. He's played in 23 games in his career. He had no tackles in two games with the Giants.\n",
      "\n",
      "If Carter and Johnson are out, another young player with some experience at free safety could be in line to make the team.\n",
      "\n",
      "With the exception of a handful of runs, the Bengals have been awful, but the good news is there may still be a spot for Carter and Johnson.<|endoftext|>This week, RPS head writer Ben Kuchera has been here at the GamesIndustry.biz offices in New York, and he's been meeting with some of the people at the company, in order to get their thoughts on the state of the games industry.\n",
      "When asked how he felt about the state of games, Ben Kuchera said, \"I think the games industry is really good right now, and it's very hard to describe. The industry is in the middle of a renaissance. The games industry, it's probably the best-run, most stable industry in the US. They've got the best employees, the best people, the best technology. They've got the best people, and they're all extremely proud of what they've achieved.\"\n",
      "He went on to say that they had a lot of good support, and that they were a \"living symbol of progress\" in the industry.\n",
      "He also said that they had the best reputation. He said, \"I think the industry would do well to have that, because the industry is the most important thing about the US, and it's very hard to be anything but a living symbol of progress and progress.\"\n",
      "So, what are you waiting for? Go and try it out now.\n",
      "Thanks to Ben for the tip!\n",
      "The team at The Sims 2 - a game Ben Kuchera played with a friend - is no longer live on Facebook.\n",
      "The Sims 2, the first Sims game, was released in 2004, and was the third of four major Sims games. The third one, The Sims 2, was released in the same year as SimCity. SimCity was the most successful SimCity game in history, selling over 20 million copies in its first year.\n",
      "The Sims 2, which was developed by EA Tiburon, sold over 10 million copies in the first year, and was the most popular SimCity game. It was also the most innovative, the most popular, and the most popular on the market in the first year of release.\n",
      "The Sims 2 was the second of four major SimCity games in the series. The first was The Sims, released in 2007. The second was The Sims 2: FreeStyle, released in 2008. The third was The Sims 2: FreeStyle 2, released in 2009. The fourth was The Sims 2: The Sims 3, released in 2010.\n",
      "BEN KUCHERA\n",
      "The Sims 2, the first SimCity game, was released in 2004. The game was developed by EA Tiburon. The game was a massive success in the first year, and the game became a landmark in the franchise. The game made the top 20 on the GameRankings, and in 2006 it was named a top 10 game.\n",
      "Tiburon, the company that developed the game, was acquired by Electronic Arts in the summer of 2007. EA Tiburon was also the developer of The Sims, but it was not developed by EA Tiburon.\n",
      "The Sims 2, the first Sims game, was released in 2004. The game was developed by EA Tiburon. The game was a massive success in the first year, and the game became a landmark in the franchise. The game made the top 20 on the GameRankings, and in 2006 it was named a top 10 game.\n",
      "Tiburon, the company that developed the game\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1') # no prefix, unconditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------\n",
      "[1]\n",
      "Name=Feraligatr\n",
      "InternalName=FERALIGATR\n",
      "Type1=ELECTRIC\n",
      "Type2=GHOST\n",
      "BaseStats=100,130,110,105,120,80\n",
      "GenderRate=Female50Percent\n",
      "GrowthRate=Medium\n",
      "BaseEXP=260\n",
      "EffortPoints=0,0,2,0,0,0\n",
      "Rareness=90\n",
      "Happiness=70\n",
      "Abilities=REGENERATOR,MEGABEATracked\n",
      "HiddenAbility=DEFIANT\n",
      "Moves=1,FURYSWIPES,1,CONFUSION,1,REVENGE,1,FAKEOUT,1,MAGNETRISE,1,FAKETEARS,1,LEECHSEED,1,SCARYFACE,1,HYPNOSIS,1,BUBBLEBEAM,1,RAZORLEAF,1,FUTURESIGHT,1,THUNDERWAVE,1,HYPNOSIS,6,SLASH,12,MEGAHORN,16,SAFEGUARD,24,SWEETSCENT,32,STOPPINGWORLD,40,GIGADRAIN,48,BULLETSURF,64,SUNNYDAY,80,SUNNYDAY,100,REVERSAL,120,SAFEGUARD,144,SUPERPOWER\n",
      "Compatibility=Humanlike\n",
      "StepsToHatch=5355\n",
      "Height=2.0\n",
      "Weight=237.0\n",
      "Color=Blue\n",
      "Shape=12\n",
      "Kind=Gigantic\n",
      "Pokedex=It is the guardian of a gigantic cave that is believed to hold ancient wisdom. It eats anything that moves in the cave, and even its own body.\n",
      "BattlerPlayerY=22\n",
      "BattlerEnemyY=29\n",
      "BattlerAltitude=13\n",
      "Evolutions=\n",
      "#-------------------------------\n",
      "[2]\n",
      "Name=Lopunny\n",
      "InternalName=LOPUNNY\n",
      "Type1=PSYCHIC\n",
      "BaseStats=60,80,60,60,80,80\n",
      "GenderRate=Genderless\n",
      "GrowthRate=Slow\n",
      "BaseEXP=184\n",
      "EffortPoints=0,0,2,0,0,0\n",
      "Rareness=75\n",
      "Happiness=70\n",
      "Abilities=LOVESCREEN,HEADBUTT\n",
      "HiddenAbility=HELPINGHAND\n",
      "Moves=1,LOWKICK,1,REST,1,BITE,5,DISARMINGVOICE,10,THUNDERWAVE,15,HEADBUTT,20,MIST,25,FROGSPLIT,30,TAKEDOWN,35,TAKEDOWN,40,SLASH,45,BITE,50,STEELWING,55,DISARMINGVOICE,60,MIST,65,CONFUSION\n",
      "EggMoves=BLOCK,CURSE,CRUSHCLAW,CRUNCH,DOUBLETEAM,DISARMINGVOICE,SPITE,WHIRLPOOL,WISH\n",
      "Compatibility=Field\n",
      "StepsToHatch=5355\n",
      "Height=0.5\n",
      "Weight=2.0\n",
      "Color=Blue\n",
      "Shape=8\n",
      "Kind=Lopunny\n",
      "Pokedex=The only Pokémon that live in caves. It builds its nests in the rocks by using thick, sticky, thick grass.\n",
      "BattlerPlayerY=33\n",
      "BattlerEnemyY=36\n",
      "BattlerAltitude=0\n",
      "Evolutions=\n",
      "#-------------------------------\n",
      "[3]\n",
      "Name=Tigrex\n",
      "InternalName=TIGREX\n",
      "Type1=PSYCHIC\n",
      "BaseStats=55,75,60,80,95,95\n",
      "GenderRate=Genderless\n",
      "GrowthRate=Slow\n",
      "BaseEXP=189\n",
      "EffortPoints=0,0,1,0,0,0\n",
      "Rareness=90\n",
      "Happiness=70\n",
      "Abilities=WILDLIFE,GROWL,LUCKYPOOL\n",
      "HiddenAbility=HELPINGHAND\n",
      "Moves=1,DISARMINGVOICE,1,FURYSWIPES,1,CONFUSION,1,REVENGE,1,FAKEOUT,1,MAGNETRISE,1,FAKETEARS,1,LEECHSEED,1,SCARYFACE,1,HYPNOSIS,1,BUBBLEBEAM,1,RAZORLEAF,1,FUTURESIGHT,1,THUNDERWAVE,1,HYPNOSIS,6,SLASH,12,MEGAHORN,16\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1', prefix=\"#-------------------------------\\n[1]\\nName=\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF4-PqF0Fl7R",
    "tags": []
   },
   "source": [
    "## Notes\n",
    "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
    "\n",
    "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
    "\n",
    "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
    "\n",
    "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
    "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text.\n",
    "\n",
    "After testing multiple prefixes and no prefix multiple times, it seemed like a good idea to restrict the outputs a bit to something that is feasible to create. Multiple different games were ran, but \"Pokemon, but\" seemed to produce very interesting results and fit the YouTube channel's typical videos.\n",
    "\n",
    "The Temperature of 0.9 seemed to produce the most variation with interesting results without being incoherent.\n",
    "\n",
    "The length, nsamples, and batch_size were chosen to produce at least 1 full title multiple times with the desired prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DKMc0fiej4N",
    "outputId": "490a4648-d973-4675-cf9a-7a48c16fd736",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------------------------------\n",
      "[1]\n",
      "Name=BarkedGylp\n",
      "InternalName=BARKEDGYLP\n",
      "Type1=NORMAL\n",
      "Base\n",
      "====================\n",
      "#-------------------------------\n",
      "[1]\n",
      "Name=Windon\n",
      "InternalName=WINDON\n",
      "Type1=DARK\n",
      "Type2=FAKUS\n",
      "BaseStats=\n",
      "====================\n",
      "#-------------------------------\n",
      "[1]\n",
      "Name=Porygon2\n",
      "InternalName=PORYGON2\n",
      "Type1=NORMAL\n",
      "BaseStats=45,\n",
      "====================\n",
      "#-------------------------------\n",
      "[1]\n",
      "Name=Spiral\n",
      "InternalName=SUNSPIRAL\n",
      "Type1=NORMAL\n",
      "BaseStats=80,75\n",
      "====================\n",
      "#-------------------------------\n",
      "[1]\n",
      "Name=Hawkdon\n",
      "InternalName=HAWCON\n",
      "Type1=DARK\n",
      "BaseStats=80,35,60\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=25,\n",
    "              temperature=0.8,\n",
    "              prefix=\"#-------------------------------\\n[1]\\nName=\",\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjjEN2Tafhl2"
   },
   "source": [
    "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
    "\n",
    "You can rerun the cells as many times as you want for even more generated texts!\n",
    "\n",
    "The same values were used here as the previous generation, but this time, it produces a txt file and far more results. This provided 100 different titles with the requested prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Fa6p6arifSL0"
   },
   "outputs": [],
   "source": [
    "gen_file = \"generated_pokemon6.txt\"\n",
    "\n",
    "gpt2.generate_to_file(sess,\n",
    "                      destination_path=gen_file,\n",
    "                      length=1000,\n",
    "                      temperature=0.85,\n",
    "                      prefix=\"#-------------------------------\\n[1]\\nName=\",\n",
    "                      nsamples=100,\n",
    "                      batch_size=20\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-LRex8lfv1g"
   },
   "source": [
    "Download the file by hand in the browser at left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTa6zf3e_9gV"
   },
   "source": [
    "Uploaded your saved checkpoint and unzip it.\n",
    "\n",
    "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
    "\n",
    "This will reset or start the tensorflow session as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fxL77nvAMAX",
    "outputId": "8938432a-3b86-4102-f32b-362721ecb897"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "if not sess:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)\n",
    "\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig-KVgkCDCKD"
   },
   "source": [
    "# Etcetera\n",
    "\n",
    "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIHiVP53FnsX"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmTXWNUygS5E"
   },
   "source": [
    "# License\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- Max's [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
    "- Original repo: [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple) by [Max Woolf](http://minimaxir.com). \n",
    "- Original [google colab](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) from Max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Train a GPT-2 Text-Generating Model w/ GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow GPU 2.6 (py39)",
   "language": "python",
   "name": "tensorflow-gpu-2.6-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
